<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Course-articles-videos-recommendation</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Personal - v2.3.0
  * Template URL: https://bootstrapmade.com/personal-free-resume-bootstrap-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <main id="main">

    <!-- ======= Portfolio Details ======= -->
    <div id="portfolio-details" class="portfolio-details">
      <div class="container">

        <div class="row">

          <div class="col-lg-8">
            <h3 class="portfolio-title">Course-articles-videos-recommendation</h3>
            <div class="owl-carousel portfolio-details-carousel">
              <img src="assets\img\projects\p06\1.png" class="img-fluid" alt="">
              <img src="assets\img\projects\p06\2.png" class="img-fluid" alt="">
              <img src="assets\img\projects\p06\3.png" class="img-fluid" alt="">
            </div>
          </div>

          <div class="col-lg-4 portfolio-info">
            <h2>Project information</h2>
            <ul>
              <li><strong>Category</strong>: AI, NLP, Machine learning, Wenbscraping, Product design, API</li>
              <li><strong>Type</strong>: Intern</li>
              <li><strong>Project date</strong>:2019 - 3months</li>
              <li><strong>Hosted by</strong>: <a href="https://www.softcenter.se/about-soft-center/" target="_blank">SoftCenter</a> </li>
              <li><strong>Github URL</strong>: <a href="https://github.com/ZA3karia/course-articles-videos-recomendation" target="_blank">repository</a></li>
              <li><strong>Presentation </strong>: <a href="assets\files\p06\p06_ZAZA_Zakaria_project.pptx">Presentation.ppt</a>  </li>
            </ul>
<article class="markdown-body entry-content container-lg" itemprop="text"><h2><a id="user-content-course-articles-videos-recommendation" class="anchor" aria-hidden="true" href="#course-articles-videos-recommendation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Course-articles-videos-recommendation</h2>
              <p>This is a project in which we are trying to create an algorithm that can recommend (articles, courses, &amp; video) based on your professional needs, by scraping indeed job entries and determining (trough NLP/NER) skills convenable to that need, filling it by determining skills provided by the online courses and articles or videos to recommend it to you.</p>
              <h2><a id="user-content-first-we-collect-the-data" class="anchor" aria-hidden="true" href="#first-we-collect-the-data"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>First, we collect the data</h2>
              <h3><a id="user-content-stationary-or-dynamic" class="anchor" aria-hidden="true" href="#stationary-or-dynamic"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Stationary or dynamic</h3>
              <p>With stationary data our agent will become less and less relevant with time passing by, in other words he will get old and start recommending for example courses of HTML5 in 2050 while there is no one use of it anymore!!!
              Therefore, our algorithm is aiming to automatically collect the data sources from internet to keep its dataset relevant! and be a little more accurate by having the possibility to control the data structure!
              That will be possible by creating a web scraping algorithm, I was here inspired by - George Liu's - article "Scraping Job Posting Data from Indeed using Selenium and BeautifulSoup»: <a href="https://towardsdatascience.com/scraping-job-posting-data-from-indeed-using-selenium-and-beautifulsoup-dfc86230baac" target="_blank" rel="nofollow">https://towardsdatascience.com/scraping-job-posting-data-from-indeed-using-selenium-and-beautifulsoup-dfc86230baac</a><br>
              his GitHub repository: <a href="https://github.com/georgeliu1998/ideal_profiles/blob/master/scrape_data.py?source=post_page---------------------------" target="_blank">https://github.com/georgeliu1998/ideal_profiles/blob/master/scrape_data.py?source=post_page---------------------------</a>
              Though it wasn't a copy/past situation, since it needed some modification cause its outdated and the fact that indeed is constantly updating their website, so the working web scraper of today will not necessary work tomorrow, but its will if you change 3 to 2 lines of code! That wasn't the case any way, I have changed every function to make the code work the way I wanted it! but the structure is pretty much the same :), for more info check out: <a href="https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/webscarping_indeed_jobs.md" target="_blank">https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/webscarping_indeed_jobs.md</a></p>
              <h2><a id="user-content-ner-on-our-data" class="anchor" aria-hidden="true" href="#ner-on-our-data"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>NER on our data</h2>
              <h3><a id="user-content-state-of-the-art" class="anchor" aria-hidden="true" href="#state-of-the-art"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>state-of-the-art</h3>
              <p>In the first time I intended to use state-of-the-art Named entity recognition, to get the best accuracy possible, so I went using Flair framework [you can find their tutorials here: <a href="https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_1_BASICS.md" target="_blank">https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_1_BASICS.md</a>]
              But they were not as accurate as I wanted them to be, neither as fast as feasible for my case, the algorithm was well rated, but it wasn't dedicated to work on my type of dataset, &amp; it was very expensive in terms of hardware consumption, up to 1h for their 'ner-fast' model to predict keywords on my data! I had to re train it to get the best of accuracy but I have no training data, and even if I had it, 1hour predicting is pretty rough, exactly if I am using a dynamic agent!!</p>
              <h3><a id="user-content-old-but-gold" class="anchor" aria-hidden="true" href="#old-but-gold"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Old but Gold</h3>
              <p>Therefor as much as I wanted to use state of the art algorithms, I went back in time to use a very basic and cheap in hardware consumption algorithm, "IDF calculations"
              And my work was mainly based on the work of - Sowmya Vivek's - article: <a href="https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34" target="_blank" rel="nofollow">https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34</a>
              for more details check out my notebook: <a href="https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/treating_indeed_dataset.ipynb" target="_blank">https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/treating_indeed_dataset.ipynb</a></p>
              <h2><a id="user-content-get-that-article" class="anchor" aria-hidden="true" href="#get-that-article"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Get that article</h2>
              <h3><a id="user-content-scrap-the-web-again" class="anchor" aria-hidden="true" href="#scrap-the-web-again"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>scrap the web again?</h3>
              <p>Now that we have got the fields that the person is interested in, and we know the up to date terms that are related to him, we need to get the best out of this information, and serve him with the best articles available in the web, therefore the first instinct that came up to my mind was to create another big dynamic dataset that contains every article related to every Field &amp; interest and then recommend them to my user. but this method is not only inconvenient and require a lot of storage but its -impossible-!!!
              most articles refused my scraping attempts unfortunately. Yeah, I can use selenium and get the data anyway! but there is a way around this!</p>
              <h3><a id="user-content-hi-google" class="anchor" aria-hidden="true" href="#hi-google"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Hi google</h3>
              <p>The Google custom search engine python REST API is a relief it made it all simple to get every piece of the data I want, and it made all the articles exposed and with a quality reference two!
              <a href="https://cse.google.com/cse/all" target="_blank" rel="nofollow">https://cse.google.com/cse/all</a>
              <a href="https://medium.com/@hemantjain1999/implementing-web-scraping-in-python-with-beautifulsoup-and-google-api-34c7282b9257" target="_blank" rel="nofollow">https://medium.com/@hemantjain1999/implementing-web-scraping-in-python-with-beautifulsoup-and-google-api-34c7282b9257</a>
              check my notebook:   <a href="https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/courses%26articles_recommendation.ipy"target="_blank" >https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/courses%26articles_recommendation.ipy</a>           for more info</p>
              <h2><a id="user-content-whats-now" class="anchor" aria-hidden="true" href="#whats-now"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>What’s now??</h2>
              <h3><a id="user-content-the-easy-way" class="anchor" aria-hidden="true" href="#the-easy-way"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>the easy way....</h3>
              <p>You can now recommend the articles right away to the user and have a good recommendation system</p>
              <h3><a id="user-content-the-juicy-way" class="anchor" aria-hidden="true" href="#the-juicy-way"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>the juicy way</h3>
              <p>But you can also take the Google CSE result and pass it to a classifier and correct it with future recommendations and finish up with a recommender system that updates frequently and personalized to each personnel!</p>
              <p>The fact that the second one is a beautiful concept we will do it ;)</p>
              <h2><a id="user-content-first-lets-understand-it" class="anchor" aria-hidden="true" href="#first-lets-understand-it"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>First let’s understand it</h2>
              <h3><a id="user-content-newspaper3k-again" class="anchor" aria-hidden="true" href="#newspaper3k-again"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>newspaper3k again</h3>
              <p>In fact, we don’t have to the machine is the one that needs to understand, and we again have the choice either use state-of-the-art algorithms or use an easy framework that doesn’t just give good result but also do the scraping for you (aka: newspaper3k)
              for more info check the readme file:
              newspaper3k test: <a href="https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/test_newspaper3k.ipynb" target="_blank">https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/test_newspaper3k.ipynb</a>
              generatino of article data: <a href="https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/Generating_article_data.ipynb" target="_blank">https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/Generating_article_data.ipynb</a>
              After that we will have got a good dataset representation of our articles, make in consideration I’ve used a lot of data that It would have been better to know exactly what feature matters, or take it all and apply dimensional reduction, (spoilers: I didn’t, but I will hopefully in the future), now that we got the articles data. We need the target to train the model, unfortunately this data can’t be scrapped NOR predict, because we need to make it relevant to the user, but we can start to be random in the beginning and it will learn as it goes ;)
              therefore, I made a Dummy data using Pandas &amp; NumPy you can check the notebook to know how I've done it:
              <a href="https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/fake_data_generation.ipynb" target="_blank">https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/fake_data_generation.ipynb</a></p>
              <h2><a id="user-content-nn-or-classic" class="anchor" aria-hidden="true" href="#nn-or-classic"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>NN or Classic</h2>
              <p>Its basically a good choice to use a normal classifier and us
              Then I merged the data, I used the Cartesian product then transformed it into a TensorFlow dataset, it would have been better if I
              used Matrices Factorization, but that is for another day.
              I then trained a Simple NN using TensorFlow &amp; Keras to recognize the patterns in my data, check my notebook:
              <a href="https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/data_preprocessing%26model_testing.ipynb" target="_blank">https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/data_preprocessing%26model_testing.ipynb</a>
              After that you can feed it to your website get the user experience feedback and make your model converge better for every person</p>
              <h2><a id="user-content-my-final-architecture" class="anchor" aria-hidden="true" href="#my-final-architecture"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>My final architecture</h2>
              <p><a href="https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/shema%20final.PNG"target="_blank">https://github.com/ZA3karia/course-articles-videos-recomendation/blob/master/shema%20final.PNG</a></p>
              </article>
          </div>

        </div>

      </div>
    </div><!-- End Portfolio Details -->

  </main><!-- End #main -->


  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script src="assets/vendor/counterup/counterup.min.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>